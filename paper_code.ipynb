{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Necessary Packages\n",
    "Here we import the necessary third party packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-24T11:05:49.980669Z",
     "end_time": "2024-05-24T11:05:51.129643Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely import Polygon, intersection, union\n",
    "from skimage.measure import find_contours\n",
    "import os\n",
    "import random\n",
    "from skimage.draw import polygon\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import img_as_ubyte\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "image = cv2.imread('../tattoo_images/2776427893_58405d2a94.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T15:32:09.182010Z",
     "end_time": "2024-05-20T15:32:09.237030Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining Functions for showing masks\n",
    "show_mask shows the mask of the image that was predicted\n",
    "show_points shows the prompting points\n",
    "show_box shows the bounding box"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T17:56:26.413491Z",
     "end_time": "2024-05-21T17:56:26.427492Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions for data pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "annotation_file = \"../tattoo_annotations.txt\"\n",
    "annotations = []\n",
    "match_pattern =r'(.+\\.jpg) (\\[.+\\])'\n",
    "split_pattern = r'[;\\s\\t\\n\\]]'\n",
    "result = {}\n",
    "with open(annotation_file) as file:\n",
    "    for input_str in file.readlines():\n",
    "        match = re.match(match_pattern, input_str)\n",
    "        if match:\n",
    "            filename = match.group(1)\n",
    "            coordinates_str = match.group(2)\n",
    "            coordinates_list = re.split(split_pattern, coordinates_str)\n",
    "            coordinates_list = [x.strip(r\"\\[\\]\") for x in coordinates_list if x != \"\"]\n",
    "            result[filename] = coordinates_list\n",
    "        else:\n",
    "            print(\"No matches!\")\n",
    "results_evaluated = {}\n",
    "for k,v in result.items():\n",
    "    results_evaluated[k] = [eval(x) for x in v]\n",
    "dirlist = os.listdir(\"../tattoo_images\")\n",
    "keylist = results_evaluated.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T17:56:40.181473Z",
     "end_time": "2024-05-21T17:56:41.841345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "points = results_evaluated[\"2776427893_58405d2a94.jpg\"]\n",
    "np.array(points)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T20:15:59.178457Z",
     "end_time": "2024-05-20T20:15:59.192487Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def polygon_to_mask(image_shape, polygon_points):\n",
    "    '''\n",
    "\n",
    "    :param image_shape: Shape of image\n",
    "    :param polygon_points: Points that are inside the polygon\n",
    "    :return: Binary mask of the polygon\n",
    "    '''\n",
    "    polygon_points = np.array(polygon_points)\n",
    "    rr, cc = polygon(polygon_points[:, 1], polygon_points[:, 0], image_shape)\n",
    "    mask = np.zeros(image_shape, dtype=np.uint8)\n",
    "    mask[rr, cc] = 1\n",
    "    return mask, rr, cc\n",
    "\n",
    "def convert_rgb_to_binary_mask(rgb_mask):\n",
    "    \"\"\"\n",
    "    Convert an RGB mask to a binary mask.\n",
    "\n",
    "    Parameters:\n",
    "    rgb_mask (np.array): RGB mask of shape (height, width, 3)\n",
    "\n",
    "    Returns:\n",
    "    np.array: Binary mask of shape (height, width)\n",
    "    \"\"\"\n",
    "    # Convert RGB mask to grayscale\n",
    "    gray_mask = rgb2gray(rgb_mask)\n",
    "    # Threshold the grayscale image to get a binary mask\n",
    "    binary_mask = img_as_ubyte(gray_mask > 0)\n",
    "\n",
    "    return binary_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T17:56:44.855988Z",
     "end_time": "2024-05-21T17:56:44.876493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_1, rr, cc = polygon_to_mask(image.shape, points)\n",
    "mask_2 = convert_rgb_to_binary_mask(mask_1)\n",
    "plt.imshow(mask_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T16:54:15.905053Z",
     "end_time": "2024-05-20T16:54:16.219679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "def random_points(mask, no_true = 1, no_false = 0):\n",
    "    '''\n",
    "    Selects n random points inside the mask, and m points outside in the background\n",
    "    :param mask: Binary mask in the shape of the image\n",
    "    :param no_true: n\n",
    "    :param no_false: m\n",
    "    :return: numpy array of points\n",
    "    '''\n",
    "    tattoo_indices = np.argwhere(mask == 255)\n",
    "    background_indices = np.argwhere(mask == 0)\n",
    "    tattoo_points = tattoo_indices[np.random.choice(len(tattoo_indices), no_true, replace=False)]\n",
    "    background_points = background_indices[np.random.choice(len(background_indices), no_false, replace=False)]\n",
    "    tattoo_points = tattoo_points[:, [1,0]]\n",
    "    background_points = background_points[:, [1,0]]\n",
    "    return tattoo_points, background_points\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T17:56:53.147308Z",
     "end_time": "2024-05-21T17:56:53.193315Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining functions for results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def iou(pred, ground_truth):\n",
    "    pred = pred.astype(int)\n",
    "    ground_truth = ground_truth.astype(int)\n",
    "    pred = pred.flatten()\n",
    "    ground_truth = ground_truth.flatten()\n",
    "    print(pred)\n",
    "    print(ground_truth)\n",
    "    intersection = np.sum(pred*ground_truth)\n",
    "    union = np.sum(pred) + np.sum(ground_truth)\n",
    "    print(intersection)\n",
    "    print(union)\n",
    "    print(np.sum(pred*ground_truth))\n",
    "    iou = intersection / union if union != 0 else 0\n",
    "    return iou"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T19:45:16.808984Z",
     "end_time": "2024-05-21T19:45:16.833155Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def fpr_fnr(pred, ground_truth):\n",
    "    pred = pred.astype(int)\n",
    "    ground_truth = ground_truth.astype(int)\n",
    "    pred = pred.flatten()\n",
    "    ground_truth = ground_truth.flatten()\n",
    "    tp = np.sum(pred * ground_truth)\n",
    "    fp = np.sum(pred * (1-ground_truth))\n",
    "    fn = np.sum((1 - pred) * ground_truth)\n",
    "    tn = np.sum((1 - pred) * (1 - ground_truth))\n",
    "    print(tp,fp,fn, tn)\n",
    "    fpr = fp/(fp+tn) if fp+tn != 0 else 0\n",
    "    fnr = fn / (fn+tp) if fn+tp != 0 else 0\n",
    "    return fpr, fnr\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T19:44:57.041276Z",
     "end_time": "2024-05-21T19:44:57.051533Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Reading\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "image = cv2.imread('../tattoo_images/2776427893_58405d2a94.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T13:49:31.861083Z",
     "end_time": "2024-05-20T13:49:31.893517Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask = polygon_to_mask(image.shape, points)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "plt.imshow(mask, interpolation= \"none\", cmap=\"jet\", alpha=0.95)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"test.svg\", format=\"svg\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T15:14:42.982255Z",
     "end_time": "2024-05-20T15:14:44.005505Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"../sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T17:57:12.154438Z",
     "end_time": "2024-05-21T17:57:35.238776Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m predictor\u001B[38;5;241m.\u001B[39mset_image(\u001B[43mimage\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T14:46:39.758873Z",
     "end_time": "2024-05-20T14:47:31.203121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T17:31:22.141123Z",
     "end_time": "2024-05-20T17:31:22.177122Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T17:31:23.010483Z",
     "end_time": "2024-05-20T17:31:23.588885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T17:31:46.085739Z",
     "end_time": "2024-05-20T17:31:46.305738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_points(input_point, input_label, plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T21:16:10.338376Z",
     "end_time": "2024-05-20T21:16:12.587890Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "[(216.049382716, 470.906579041),\n (219.416386083, 451.519986809),\n (249.158249158, 446.516995266),\n (232.323232323, 428.38115092),\n (232.323232323, 418.375167833),\n (242.424242424, 397.112453773),\n (253.086419753, 392.734836172),\n (258.698092031, 398.363201659),\n (265.432098765, 412.121428404),\n (269.36026936, 417.124419947),\n (267.676767677, 430.882646692),\n (267.115600449, 435.260264293),\n (291.245791246, 461.525969897),\n (292.929292929, 461.525969897),\n (296.296296296, 459.649848068),\n (296.296296296, 441.514003722),\n (301.346801347, 436.511012179),\n (315.375982043, 438.387134008),\n (322.671156004, 435.885638236),\n (318.74298541, 426.505029092),\n (299.663299663, 409.619932632),\n (292.368125701, 406.493062917),\n (276.655443322, 404.616941088),\n (265.432098765, 387.731844629),\n (311.447811448, 368.345252397),\n (300.785634119, 355.212399595),\n (281.144781145, 317.064589075),\n (273.849607183, 290.798883471),\n (278.900112233, 280.167526441),\n (274.971941639, 260.155560267),\n (263.748597082, 255.777942666),\n (258.698092031, 248.273455351),\n (260.381593715, 221.382375804),\n (267.676767677, 199.494287801),\n (301.907968575, 148.213624479),\n (323.232323232, 115.068805503),\n (335.578002245, 75.6702470969),\n (333.333333333, 50.029915436),\n (305.836139169, 25.6403316609),\n (293.490460157, 16.8850964596),\n (290.684624018, 21.8880880032),\n (286.756453423, 28.7672013757),\n (283.950617284, 38.1478105199),\n (286.195286195, 55.6582809225),\n (278.900112233, 72.5433773821),\n (273.849607183, 93.1807174995),\n (237.934904602, 141.334511107),\n (228.395061728, 152.59124208),\n (217.171717172, 172.603208254),\n (208.754208754, 200.745035687),\n (204.826038159, 225.134619462),\n (182.940516274, 229.512237062),\n (168.35016835, 199.494287801),\n (179.573512907, 191.989800485),\n (149.270482604, 166.974842768),\n (136.924803591, 164.473346996),\n (140.291806958, 180.733069512),\n (143.097643098, 205.74802723),\n (144.781144781, 210.751018774),\n (156.565656566, 205.74802723),\n (161.616161616, 216.379384261),\n (173.400673401, 236.391350435),\n (163.2996633, 252.025699009),\n (157.126823793, 272.663039126),\n (157.126823793, 289.548135586),\n (162.738496072, 307.683979931),\n (153.759820426, 313.312345418),\n (140.291806958, 326.44519822),\n (135.241301908, 342.704920736),\n (130.751964085, 360.840765082),\n (140.852974186, 391.484088286),\n (138.047138047, 397.737827716),\n (139.730639731, 402.115445316),\n (144.781144781, 409.619932632),\n (158.249158249, 413.997550233),\n (174.523007856, 419.000541776),\n (180.134680135, 425.254281206),\n (193.041526375, 450.894612867),\n (204.826038159, 465.278213554),\n (215.488215488, 470.906579041)]"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T17:54:58.939244Z",
     "end_time": "2024-05-20T17:54:59.003278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 0.0)"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T18:59:12.146460Z",
     "end_time": "2024-05-20T18:59:12.166458Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T19:01:25.536927Z",
     "end_time": "2024-05-20T19:01:25.556130Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T19:01:11.653778Z",
     "end_time": "2024-05-20T19:01:11.671782Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T19:01:54.226838Z",
     "end_time": "2024-05-20T19:01:54.259835Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writing all the jpg-files to a txt file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1\n",
      "split_2\n",
      "split_3\n",
      "split_4\n",
      "split_5\n"
     ]
    }
   ],
   "source": [
    "path = \"../DeMSI\"\n",
    "for diri in os.listdir(path):\n",
    "    path_to_files = os.listdir(os.path.join(path,diri))\n",
    "    with open(f\"../DeMSI/{diri}/{diri}.txt\", \"w\") as fi:\n",
    "        print(diri)\n",
    "        for file in path_to_files:\n",
    "            fi.writelines(f\"{file}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T20:36:50.984046Z",
     "end_time": "2024-05-20T20:36:51.025276Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now: get the polygons! NO the bounding box!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "def get_bounding_box(value):\n",
    "    first_elements = [t[0] for t in value]\n",
    "    second_elements = [t[1] for t in value]\n",
    "\n",
    "    max_first = max(first_elements)\n",
    "    min_first = min(first_elements)\n",
    "    max_second = max(second_elements)\n",
    "    min_second = min(second_elements)\n",
    "    return np.array([min_first, min_second, max_first, max_second])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T21:08:08.025670Z",
     "end_time": "2024-05-20T21:08:08.052701Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "data": {
      "text/plain": "array([130.75196408,  16.88509646, 335.57800224, 470.90657904])"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T21:08:25.590991Z",
     "end_time": "2024-05-20T21:08:25.611992Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Workprocess\n",
    "What we will do:\n",
    "    - imread the picture\n",
    "    - read the polygon lines from the txt file\n",
    "    - calculate fpr, fnr, IoU for ALL images!\n",
    "    - save the result in a txt or csv file\n",
    "    - calculate mean of this all"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "320790\n",
      "477855\n",
      "320790\n",
      "320790 -163725 0 30435\n",
      "0.6713124274099884 1.2283367094305648 0.0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "20078700\n",
      "20285558\n",
      "20078700\n",
      "20078700 -19991692 119850 -19358\n",
      "0.9898026960855599 0.9990326344694557 0.005933594243151118\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "69615\n",
      "85302\n",
      "69615\n",
      "69615 -53928 0 150313\n",
      "0.8161004431314623 -0.5595061472220781 0.0\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "24990\n",
      "5541804\n",
      "24990\n",
      "24990 -23571 5515395 -5350314\n",
      "0.004509361933406522 0.00438621220960255 0.9954894831315875\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "1116135\n",
      "2338306\n",
      "1116135\n",
      "1116135 -1104704 1210740 -1055671\n",
      "0.47732632084936705 0.5113482612972285 0.5203287671232877\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "3981570\n",
      "4997307\n",
      "3981570\n",
      "3981570 -3965688 999855 -877737\n",
      "0.7967431258475816 0.8187776212081327 0.20071666240081903\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "12391980\n",
      "12581434\n",
      "12391980\n",
      "12391980 -12340736 138210 -1954\n",
      "0.9849417800864353 0.999841687671002 0.011030159957670234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nweiand\\AppData\\Local\\Temp\\ipykernel_16716\\2120409559.py:25: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10,10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "8726355\n",
      "8894176\n",
      "8726355\n",
      "8726355 -8559044 510 19679\n",
      "0.9811313605667349 1.002304503906321 5.84402302545072e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 40\u001B[0m\n\u001B[0;32m     36\u001B[0m             \u001B[38;5;28mprint\u001B[39m(io, fpr, fnr)\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m(io_list, fpr_list, fnr_list)\n\u001B[1;32m---> 40\u001B[0m io_list, fpr_list, fnr_list \u001B[38;5;241m=\u001B[39m \u001B[43mall_combine_save_number\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[35], line 10\u001B[0m, in \u001B[0;36mall_combine_save_number\u001B[1;34m(true, false, bounding_box)\u001B[0m\n\u001B[0;32m      8\u001B[0m mask, rr, cc \u001B[38;5;241m=\u001B[39m polygon_to_mask(image\u001B[38;5;241m.\u001B[39mshape, value)\n\u001B[0;32m      9\u001B[0m mask \u001B[38;5;241m=\u001B[39m convert_rgb_to_binary_mask(mask)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Create Prompt Points\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m bounding_box:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\segment_anything\\predictor.py:60\u001B[0m, in \u001B[0;36mSamPredictor.set_image\u001B[1;34m(self, image, image_format)\u001B[0m\n\u001B[0;32m     57\u001B[0m input_image_torch \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(input_image, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     58\u001B[0m input_image_torch \u001B[38;5;241m=\u001B[39m input_image_torch\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()[\u001B[38;5;28;01mNone\u001B[39;00m, :, :, :]\n\u001B[1;32m---> 60\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_torch_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_image_torch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\segment_anything\\predictor.py:89\u001B[0m, in \u001B[0;36mSamPredictor.set_torch_image\u001B[1;34m(self, transformed_image, original_image_size)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(transformed_image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:])\n\u001B[0;32m     88\u001B[0m input_image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpreprocess(transformed_image)\n\u001B[1;32m---> 89\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_image\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_image_set \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:112\u001B[0m, in \u001B[0;36mImageEncoderViT.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    109\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_embed\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks:\n\u001B[1;32m--> 112\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mblk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneck(x\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:174\u001B[0m, in \u001B[0;36mBlock.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    171\u001B[0m     H, W \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m    172\u001B[0m     x, pad_hw \u001B[38;5;241m=\u001B[39m window_partition(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size)\n\u001B[1;32m--> 174\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;66;03m# Reverse window partition\u001B[39;00m\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:234\u001B[0m, in \u001B[0;36mAttention.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    231\u001B[0m attn \u001B[38;5;241m=\u001B[39m (q \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale) \u001B[38;5;241m@\u001B[39m k\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_rel_pos:\n\u001B[1;32m--> 234\u001B[0m     attn \u001B[38;5;241m=\u001B[39m \u001B[43madd_decomposed_rel_pos\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrel_pos_h\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrel_pos_w\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m attn \u001B[38;5;241m=\u001B[39m attn\u001B[38;5;241m.\u001B[39msoftmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    237\u001B[0m x \u001B[38;5;241m=\u001B[39m (attn \u001B[38;5;241m@\u001B[39m v)\u001B[38;5;241m.\u001B[39mview(B, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, H, W, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m)\u001B[38;5;241m.\u001B[39mreshape(B, H, W, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\biometrics\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:349\u001B[0m, in \u001B[0;36madd_decomposed_rel_pos\u001B[1;34m(attn, q, rel_pos_h, rel_pos_w, q_size, k_size)\u001B[0m\n\u001B[0;32m    347\u001B[0m q_h, q_w \u001B[38;5;241m=\u001B[39m q_size\n\u001B[0;32m    348\u001B[0m k_h, k_w \u001B[38;5;241m=\u001B[39m k_size\n\u001B[1;32m--> 349\u001B[0m Rh \u001B[38;5;241m=\u001B[39m \u001B[43mget_rel_pos\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq_h\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_h\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrel_pos_h\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    350\u001B[0m Rw \u001B[38;5;241m=\u001B[39m get_rel_pos(q_w, k_w, rel_pos_w)\n\u001B[0;32m    352\u001B[0m B, _, dim \u001B[38;5;241m=\u001B[39m q\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def all_combine_save_number(true=1, false=1, bounding_box = False):\n",
    "    io_list = []\n",
    "    fpr_list = []\n",
    "    fnr_list = []\n",
    "    for key, value in results_evaluated.items():\n",
    "        image = cv2.imread(f\"../tattoo_images/{key}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask, rr, cc = polygon_to_mask(image.shape, value)\n",
    "        mask = convert_rgb_to_binary_mask(mask)\n",
    "        predictor.set_image(image)\n",
    "        # Create Prompt Points\n",
    "        if not bounding_box:\n",
    "            tattoo, background = random_points(mask, true, false)\n",
    "            input_points = np.concatenate((tattoo, background))\n",
    "            input_label = np.concatenate((np.ones(true), np.zeros(false)))\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=input_points,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=True,\n",
    "            )\n",
    "            max_mask = masks[np.argmax(scores)]\n",
    "            io = iou(max_mask, mask)\n",
    "            fpr, fnr = fpr_fnr(max_mask, mask)\n",
    "            for i, (mask_pred, score) in enumerate(zip(masks, scores)):\n",
    "                plt.figure(figsize=(10,10))\n",
    "                overlay = image.copy()\n",
    "                overlay[mask_pred == True] = (0,255,0)\n",
    "                overlay[mask == True] = (255,0,0)\n",
    "                image = cv2.addWeighted(overlay, 0.3, image, 0.7, 0)\n",
    "                for point in input_points:\n",
    "                    cv2.circle(image, (point[0], point[1]), 5, (0,0,255), -1)\n",
    "                plt.imsave(f\"../mask/{key}_mask_{i+1}_score_{score:.3f}.jpg\", image)\n",
    "            io_list.append(io)\n",
    "            fpr_list.append(fpr)\n",
    "            fnr_list.append(fnr)\n",
    "            print(io, fpr, fnr)\n",
    "    return(io_list, fpr_list, fnr_list)\n",
    "\n",
    "\n",
    "io_list, fpr_list, fnr_list = all_combine_save_number()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T18:08:37.512558Z",
     "end_time": "2024-05-21T18:08:53.673184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T21:39:42.068506Z",
     "end_time": "2024-05-20T21:40:42.479030Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "io_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T21:40:57.435007Z",
     "end_time": "2024-05-20T21:40:57.495005Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
